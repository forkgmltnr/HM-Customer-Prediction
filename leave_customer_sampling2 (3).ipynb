{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_clothes_no = pd.read_csv('./data/df_colthes_no.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.0, 5.0, 11.0, 26.0, 1319.0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_id_shop_count = df_clothes_no.pivot_table(index = 'customer_label',\n",
    "                                         values = 'article_id',\n",
    "                                         aggfunc='count'\n",
    "                                    \n",
    ")\n",
    "\n",
    "customer_id_shop_count.sort_values(by = 'article_id', ascending = False)\n",
    "\n",
    "Q1, Q2, Q3, Q4, Q5 = np.percentile(customer_id_shop_count.values, [20, 40, 60, 80, 100])\n",
    "Q1, Q2, Q3, Q4, Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(279796, 242458, 241167, 245132, 241678)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_id_1_2_shop_count = customer_id_shop_count[(customer_id_shop_count['article_id'] >= 1) & (customer_id_shop_count['article_id'] <= 2)].index\n",
    "customer_id_3_5_shop_count = customer_id_shop_count[(customer_id_shop_count['article_id'] >= 3) & (customer_id_shop_count['article_id'] <= 5)].index\n",
    "customer_id_6_11_shop_count = customer_id_shop_count[(customer_id_shop_count['article_id'] >= 6) & (customer_id_shop_count['article_id'] <= 11)].index\n",
    "customer_id_12_26_shop_count = customer_id_shop_count[(customer_id_shop_count['article_id'] >= 12) & (customer_id_shop_count['article_id'] <= 26)].index\n",
    "customer_id_27_1319_shop_count = customer_id_shop_count[(customer_id_shop_count['article_id'] >= 27) & (customer_id_shop_count['article_id'] <= 1319)].index\n",
    "len(customer_id_1_2_shop_count), len(customer_id_3_5_shop_count), len(customer_id_6_11_shop_count), len(customer_id_12_26_shop_count), len(customer_id_27_1319_shop_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_size = 48000\n",
    "\n",
    "np.random.seed(13)\n",
    "sample_customer_id_1_2 = np.random.choice(customer_id_1_2_shop_count, size = sampling_size, replace = False)\n",
    "np.random.seed(13)\n",
    "sample_customer_id_3_5 = np.random.choice(customer_id_3_5_shop_count, size = sampling_size, replace = False)\n",
    "np.random.seed(13)\n",
    "sample_customer_id_6_11 = np.random.choice(customer_id_6_11_shop_count, size = sampling_size, replace = False)\n",
    "np.random.seed(13)\n",
    "sample_customer_id_12_26 = np.random.choice(customer_id_12_26_shop_count, size = sampling_size, replace = False)\n",
    "np.random.seed(13)\n",
    "sample_customer_id_27_1319 = np.random.choice(customer_id_27_1319_shop_count, size = sampling_size, replace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_customer_df_1_2 = df_clothes_no[df_clothes_no['customer_label'].isin(sample_customer_id_1_2)]\n",
    "sample_customer_df_3_5 = df_clothes_no[df_clothes_no['customer_label'].isin(sample_customer_id_3_5)]\n",
    "sample_customer_df_6_11 = df_clothes_no[df_clothes_no['customer_label'].isin(sample_customer_id_6_11)]\n",
    "sample_customer_df_12_26 = df_clothes_no[df_clothes_no['customer_label'].isin(sample_customer_id_12_26)]\n",
    "sample_customer_df_27_1319 = df_clothes_no[df_clothes_no['customer_label'].isin(sample_customer_id_27_1319)]\n",
    "\n",
    "\n",
    "df_clothes_no_sample = pd.concat([sample_customer_df_1_2, sample_customer_df_3_5,\n",
    "                                    sample_customer_df_6_11, sample_customer_df_12_26,\n",
    "                                    sample_customer_df_27_1319])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4446162 entries, 0 to 4446161\n",
      "Data columns (total 10 columns):\n",
      " #   Column                      Dtype  \n",
      "---  ------                      -----  \n",
      " 0   t_dat                       object \n",
      " 1   customer_label              int64  \n",
      " 2   age                         float64\n",
      " 3   article_id                  int64  \n",
      " 4   price                       float64\n",
      " 5   prod_name                   object \n",
      " 6   product_type_no             int64  \n",
      " 7   graphical_appearance_no     int64  \n",
      " 8   perceived_colour_master_id  int64  \n",
      " 9   garment_group_no            int64  \n",
      "dtypes: float64(2), int64(6), object(2)\n",
      "memory usage: 339.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_clothes_no_sample.reset_index(inplace = True, drop = True)\n",
    "df_clothes_no_sample.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4446162 entries, 0 to 4446161\n",
      "Data columns (total 10 columns):\n",
      " #   Column                      Dtype  \n",
      "---  ------                      -----  \n",
      " 0   t_dat                       object \n",
      " 1   customer_label              int64  \n",
      " 2   age                         float64\n",
      " 3   article_id                  int64  \n",
      " 4   price                       float64\n",
      " 5   prod_name                   object \n",
      " 6   product_type_no             int64  \n",
      " 7   graphical_appearance_no     int64  \n",
      " 8   perceived_colour_master_id  int64  \n",
      " 9   garment_group_no            int64  \n",
      "dtypes: float64(2), int64(6), object(2)\n",
      "memory usage: 339.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_clothes_no_sample.sort_values(['customer_label', 't_dat'])\n",
    "df_clothes_no_sample.reset_index(inplace = True, drop = True)\n",
    "df_clothes_no_sample.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clothes_no_sample.to_parquet('./data/df_clothes_no_sample.parquet.gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ArrowMemoryError",
     "evalue": "realloc of size 8388608 failed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mArrowMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\edgar\\Documents\\machine\\머신러닝프로젝트\\ML\\leave_customer_sampling2 (3).ipynb Cell 9\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/edgar/Documents/machine/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/ML/leave_customer_sampling2%20%283%29.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/edgar/Documents/machine/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/ML/leave_customer_sampling2%20%283%29.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m a \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_parquet(\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mD:\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39m머신러닝 프로젝트\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39msample\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mdf_clothes_no_sample6.parquet.gzip\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/edgar/Documents/machine/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/ML/leave_customer_sampling2%20%283%29.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m a\n",
      "File \u001b[1;32mc:\\Users\\edgar\\miniconda3\\envs\\ds_study\\lib\\site-packages\\pandas\\io\\parquet.py:503\u001b[0m, in \u001b[0;36mread_parquet\u001b[1;34m(path, engine, columns, storage_options, use_nullable_dtypes, **kwargs)\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    457\u001b[0m \u001b[39mLoad a parquet object from the file path, returning a DataFrame.\u001b[39;00m\n\u001b[0;32m    458\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    499\u001b[0m \u001b[39mDataFrame\u001b[39;00m\n\u001b[0;32m    500\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    501\u001b[0m impl \u001b[39m=\u001b[39m get_engine(engine)\n\u001b[1;32m--> 503\u001b[0m \u001b[39mreturn\u001b[39;00m impl\u001b[39m.\u001b[39;49mread(\n\u001b[0;32m    504\u001b[0m     path,\n\u001b[0;32m    505\u001b[0m     columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[0;32m    506\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m    507\u001b[0m     use_nullable_dtypes\u001b[39m=\u001b[39;49muse_nullable_dtypes,\n\u001b[0;32m    508\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m    509\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\edgar\\miniconda3\\envs\\ds_study\\lib\\site-packages\\pandas\\io\\parquet.py:251\u001b[0m, in \u001b[0;36mPyArrowImpl.read\u001b[1;34m(self, path, columns, use_nullable_dtypes, storage_options, **kwargs)\u001b[0m\n\u001b[0;32m    244\u001b[0m path_or_handle, handles, kwargs[\u001b[39m\"\u001b[39m\u001b[39mfilesystem\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m _get_path_or_handle(\n\u001b[0;32m    245\u001b[0m     path,\n\u001b[0;32m    246\u001b[0m     kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mfilesystem\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m),\n\u001b[0;32m    247\u001b[0m     storage_options\u001b[39m=\u001b[39mstorage_options,\n\u001b[0;32m    248\u001b[0m     mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    249\u001b[0m )\n\u001b[0;32m    250\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 251\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapi\u001b[39m.\u001b[39;49mparquet\u001b[39m.\u001b[39;49mread_table(\n\u001b[0;32m    252\u001b[0m         path_or_handle, columns\u001b[39m=\u001b[39;49mcolumns, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[0;32m    253\u001b[0m     )\u001b[39m.\u001b[39mto_pandas(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mto_pandas_kwargs)\n\u001b[0;32m    254\u001b[0m     \u001b[39mif\u001b[39;00m manager \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39marray\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    255\u001b[0m         result \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39m_as_manager(\u001b[39m\"\u001b[39m\u001b[39marray\u001b[39m\u001b[39m\"\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\edgar\\miniconda3\\envs\\ds_study\\lib\\site-packages\\pyarrow\\parquet\\core.py:3002\u001b[0m, in \u001b[0;36mread_table\u001b[1;34m(source, columns, use_threads, metadata, schema, use_pandas_metadata, read_dictionary, memory_map, buffer_size, partitioning, filesystem, filters, use_legacy_dataset, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, decryption_properties, thrift_string_size_limit, thrift_container_size_limit)\u001b[0m\n\u001b[0;32m   2991\u001b[0m         \u001b[39m# TODO test that source is not a directory or a list\u001b[39;00m\n\u001b[0;32m   2992\u001b[0m         dataset \u001b[39m=\u001b[39m ParquetFile(\n\u001b[0;32m   2993\u001b[0m             source, metadata\u001b[39m=\u001b[39mmetadata, read_dictionary\u001b[39m=\u001b[39mread_dictionary,\n\u001b[0;32m   2994\u001b[0m             memory_map\u001b[39m=\u001b[39mmemory_map, buffer_size\u001b[39m=\u001b[39mbuffer_size,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2999\u001b[0m             thrift_container_size_limit\u001b[39m=\u001b[39mthrift_container_size_limit,\n\u001b[0;32m   3000\u001b[0m         )\n\u001b[1;32m-> 3002\u001b[0m     \u001b[39mreturn\u001b[39;00m dataset\u001b[39m.\u001b[39;49mread(columns\u001b[39m=\u001b[39;49mcolumns, use_threads\u001b[39m=\u001b[39;49muse_threads,\n\u001b[0;32m   3003\u001b[0m                         use_pandas_metadata\u001b[39m=\u001b[39;49muse_pandas_metadata)\n\u001b[0;32m   3005\u001b[0m warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   3006\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mPassing \u001b[39m\u001b[39m'\u001b[39m\u001b[39muse_legacy_dataset=True\u001b[39m\u001b[39m'\u001b[39m\u001b[39m to get the legacy behaviour is \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   3007\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mdeprecated as of pyarrow 8.0.0, and the legacy implementation will \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   3008\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mbe removed in a future version.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   3009\u001b[0m     \u001b[39mFutureWarning\u001b[39;00m, stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m   3011\u001b[0m \u001b[39mif\u001b[39;00m ignore_prefixes \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\edgar\\miniconda3\\envs\\ds_study\\lib\\site-packages\\pyarrow\\parquet\\core.py:2630\u001b[0m, in \u001b[0;36m_ParquetDatasetV2.read\u001b[1;34m(self, columns, use_threads, use_pandas_metadata)\u001b[0m\n\u001b[0;32m   2622\u001b[0m         index_columns \u001b[39m=\u001b[39m [\n\u001b[0;32m   2623\u001b[0m             col \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m _get_pandas_index_columns(metadata)\n\u001b[0;32m   2624\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(col, \u001b[39mdict\u001b[39m)\n\u001b[0;32m   2625\u001b[0m         ]\n\u001b[0;32m   2626\u001b[0m         columns \u001b[39m=\u001b[39m (\n\u001b[0;32m   2627\u001b[0m             \u001b[39mlist\u001b[39m(columns) \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mset\u001b[39m(index_columns) \u001b[39m-\u001b[39m \u001b[39mset\u001b[39m(columns))\n\u001b[0;32m   2628\u001b[0m         )\n\u001b[1;32m-> 2630\u001b[0m table \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset\u001b[39m.\u001b[39;49mto_table(\n\u001b[0;32m   2631\u001b[0m     columns\u001b[39m=\u001b[39;49mcolumns, \u001b[39mfilter\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_filter_expression,\n\u001b[0;32m   2632\u001b[0m     use_threads\u001b[39m=\u001b[39;49muse_threads\n\u001b[0;32m   2633\u001b[0m )\n\u001b[0;32m   2635\u001b[0m \u001b[39m# if use_pandas_metadata, restore the pandas metadata (which gets\u001b[39;00m\n\u001b[0;32m   2636\u001b[0m \u001b[39m# lost if doing a specific `columns` selection in to_table)\u001b[39;00m\n\u001b[0;32m   2637\u001b[0m \u001b[39mif\u001b[39;00m use_pandas_metadata:\n",
      "File \u001b[1;32mc:\\Users\\edgar\\miniconda3\\envs\\ds_study\\lib\\site-packages\\pyarrow\\_dataset.pyx:556\u001b[0m, in \u001b[0;36mpyarrow._dataset.Dataset.to_table\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\edgar\\miniconda3\\envs\\ds_study\\lib\\site-packages\\pyarrow\\_dataset.pyx:3638\u001b[0m, in \u001b[0;36mpyarrow._dataset.Scanner.to_table\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\edgar\\miniconda3\\envs\\ds_study\\lib\\site-packages\\pyarrow\\error.pxi:144\u001b[0m, in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\edgar\\miniconda3\\envs\\ds_study\\lib\\site-packages\\pyarrow\\error.pxi:117\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mArrowMemoryError\u001b[0m: realloc of size 8388608 failed"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "a = pd.read_parquet(r'D:\\머신러닝 프로젝트\\sample\\df_clothes_no_sample6.parquet.gzip')\n",
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
